---
title: "P8106 Final Project"
author: "Phoebe Mo(km3624), Stella Li(cl4043), Yihan Feng()"
date: "5/7/2021"
output:
  pdf_document:
    latex_engine: xelatex
---


```{r warning=FALSE, message=FALSE}
library(tidyverse)
library(RColorBrewer)
library(factoextra)
library(RColorBrewer)
library(gplots)
library(randomForest)
library(e1071)
library(ranger)
library(gbm)
library(xgboost)
library(lattice)
library(caret)
```

# 1. INTRODUCTION

## 1.1 Motivation and Objective

Pokemon are fictional creatures, which can be captured by players and trained to battle each other in the augmented reality game PokÃ©mon Go!. In this project, we use a dataset from Kaggle that contains different attributes and catch rates for 721 unique Pokemons. We try to understand the relationship between Pokemons' different attributes and their respective catch rates. Here are some questions we want to answer: Which predictor(s) play important roles in predicting catch rates? Which type of model (linear or non-linear) serves as a better method to predict the catch rate?

## 1.2 Data Preparation and Cleaning

The original dataset has 20 predictors such as HP, and the outcome 'catch_rate'. After cleaning the names of these variables, I did the following steps to clean the data:

1.2.1 Notice that 'type_2' and 'egg_group_2' are indicators of if a pokemon has a second type or belongs to a second egg group. The 'Null' values in the data means the pokemon does not has the second type/group, so I changed them into "none" to make them as a category to be meaningful;

1.2.2 The 'generation' predictor is originally a numeric type, but it has only 6 integer values, so I decided to mutate it to be categorical;

1.2.3. Irrelevant variables 'number' and 'name' are dropped. 'total', which is the total base battle statistic for each pokemon, is calculated and reflected in other battle attributes such as 'hp' and 'attack'. So I dropped it to avoid intercollinearity. Later, after plotting the correlation map, I found 'weight_kg' and 'height_m' has relatively high correlation(correlation plot is shown in section 2). After consideration,  I chose to drop 'height_m' since it may has less effect on catch rate compared to 'weight_kg'. 'has_gender' is also dropped because all values are "TRUE".

```{r message=FALSE, warning=FALSE}
# data input
pkmn.df = read.csv("./pokemon.csv") %>%
  janitor::clean_names() %>%
  mutate(type_2 = replace_na(type_2, "none"),
         egg_group_2 = replace_na(egg_group_2, "none")
         ) %>%
  dplyr::select(-number, -total, -name, -has_gender) %>%
  na.omit()

factor.cols = c("type_1", "type_2", "is_legendary", "color", "egg_group_1", "egg_group_2", "has_mega_evolution", "body_style")

pkmn.df = pkmn.df %>% 
  mutate_at(factor.cols, funs(factor(.)))

# set training and testing
trRows = createDataPartition(pkmn.df$catch_rate,
                             p = 0.75,
                             list = FALSE)
```

# 2. Exploratory Analysis / Visualization

```{r}
theme1 <- trellis.par.get()
theme1$plot.symbol$col <- rgb(.2, .4, .2, .5) 
theme1$plot.symbol$pch <- 16
theme1$plot.line$col <- rgb(.8, .1, .1, 1) 
theme1$plot.line$lwd <- 2 
theme1$strip.background$col <- rgb(.0, .2, .6, .2) 
trellis.par.set(theme1)
featurePlot(x = pkmn.df[, 3:8], y = pkmn.df$catch_rate,
            plot = "scatter",
            span = .5,
            labels = c("Predictors","catch_rate"), type = c("p", "smooth"), layout = c(2,3))
```

# 3. Models

## 3.1 Bagging, Boosting, Random Forest

```{r}
# Boosting
ctrl <- trainControl(method = "cv") 

gbm.grid <- expand.grid(n.trees = c(2000,3000,4000),
                        interaction.depth = 1:4,
                        shrinkage = c(0.001,0.003,0.005),
                        n.minobsinnode = c(1,10))
set.seed(1)
gbm.fit <- train(catch_rate ~ ., 
                 pkmn.df[trRows,], 
                 method = "gbm",
                 tuneGrid = gbm.grid,
                 trControl = ctrl,
                 verbose = FALSE)

gbm.pred = predict(gbm.fit, newdata = pkmn.df[-trRows,])
gbm.rmse = RMSE(gbm.pred, pkmn.df$catch_rate[-trRows])
gbm.rmse

ggplot(gbm.fit, highlight = TRUE)
```

```{r}
# Random Forest
set.seed(2021)

rf.fit = randomForest(catch_rate ~ .,
                      pkmn.df,
                      subset = trRows,
                      mtry = 6)

rf.pred = predict(rf.fit, newdata = pkmn.df[-trRows,])
rf.rmse = RMSE(pred.rf, pkmn.df$catch_rate[-trRows])
rf.rmse

# Bagging
set.seed(2021)
bagging <- randomForest(catch_rate ~ .,
                        pkmn.df,
                        subset = trRows,
                        mtry = 19)

# fast implementation
set.seed(2021)
rf2.fit <- ranger(catch_rate ~ .,
              pkmn.df[trRows,],
              mtry = 6) 

pred.rf2 <- predict(rf2.fit, data = pkmn.df[-trRows,])$predictions
rf.rmse2 = RMSE(pred.rf2, pkmn.df$catch_rate[-trRows])
rf.rmse2
```

## 3.2 SVM

```{r}
svmr.fit = tune.svm(catch_rate ~. ,
                    data = pkmn.df[trRows,],
                    kernel = "radial",
                    epsilon = exp(seq(-5, 0, len = 20)),
                    gamma = exp(seq(-6, -2, len = 10)))

svmr.pred = predict(svmr.fit$best.model, newdata = pkmn.df[-trRows,])
svmr.rmse = RMSE(svmr.pred, pkmn.df$catch_rate[-trRows])
```

```{r}
resamp <- resamples(list(rf = rf.fit, rf2 = rf2.fit, gbm = gbm.fit, svmr = svmr.fit))
summary(resamp)
```

## 3.3 Clustering

In order to have a better visualization of the relationship between the pokemon and their different attributes, we use both k-means clustering and hierarchical clustering to group similar pokemons together. Here, we use only numerical variables.
As can see from k-means clustering, we use the optimal number of clusters = 3 and use Euclidean distance to decide the similarity. From the plot briefly, cluster 1 tends to has lower hp, cluster 2 has lower catch_rate, and cluster 3 has relatively higher weight and defense.
For the hierarchical clustering, we use complete linkage(maximal inter-cluster dissimilarity) and euclidean distance. Since hierarchical clustering provides us all the possible combinations of clusters, to visualize, we made a heat map to see how all the variables vary for each observation. From the heat map, we found pokemons that have higher hp, height, and weight tend to have lower catch_rate, whereas those which have relatively low combat attributes tend to have higher catch_rate.

```{r}
# reorganize data to be used
poke_cluster = read_csv("./pokemon.csv") %>%
  janitor::clean_names() %>%
  dplyr::select(hp, attack, defense, sp_atk, sp_def, speed, height_m, weight_kg, catch_rate) %>%
  na.omit() %>%
  scale()

# k-mean clustering, using optimal number of clusters = 3
optimal_cluster = fviz_nbclust(poke_cluster, FUNcluster = kmeans, method = "silhouette")
set.seed(1)
cluster_km = kmeans(poke_cluster, centers = 3, nstart = 30)
cluster_km_vis = fviz_cluster(list(data = poke_cluster, cluster = cluster_km$cluster),
                              ellipse.type = "convex",
                              geom = c("point", "text"),
                              labelsize = 5,
                              palette = "Dark2") + labs(title = "K-means Clustering")

# show k-means clustering plot
cluster_km_vis

# hierarchical clustering
col1 = colorRampPalette(brewer.pal(9, "PRGn"))(100)

# show hierarchical clustering heat map
heatmap.2(t(poke_cluster),
          col = col1, keysize = 0.9, key.par = list(cex = 0.5),
          trace = "none", key = TRUE, cexCol = 0.75,
          margins = c(10, 10))

# check for different clusters' members
hc_complete = hclust(dist(poke_cluster), method = "complete")
hc_dendrogram = fviz_dend(hc_complete, k = 8, cex = 0.3, palette = "jco",
             color_labels_by_k = TRUE,
             rect = TRUE, rect_fill = TRUE, rect_border = "jco",
             labels_track_height = 2.5)

# for example, for group_8 members, they have high weight, high height, high hp, and have other high attributes relatively
group_8 = poke_cluster[cutree(hc_complete, 8) == 8, ]
```

# 4. Conclusions

# 5. Limitations
